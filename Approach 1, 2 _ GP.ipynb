{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (RBF,Matern, ConstantKernel,WhiteKernel,RationalQuadratic,Exponentiation,ExpSineSquared,\n",
    "                                              DotProduct,\n",
    "                                              ConstantKernel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_features = pd.read_csv('./dengue_features_test.csv',index_col=[0,1,2])\n",
    "\n",
    "\n",
    "# load the provided data\n",
    "train_features = pd.read_csv('./dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "train_labels = pd.read_csv('./dengue_labels_train.csv',\n",
    "                           index_col=[0,1,2])\n",
    "\n",
    "\n",
    "\n",
    "# features used for approach 1 \n",
    "features = [ 'ndvi_sw','reanalysis_dew_point_temp_k', 'reanalysis_specific_humidity_g_per_kg', 'reanalysis_min_air_temp_k',\n",
    "               'station_min_temp_c',  'station_max_temp_c']\n",
    "\n",
    "# features used for approach 2\n",
    "features2 = ['reanalysis_min_air_temp_k','station_min_temp_c','reanalysis_dew_point_temp_k']\n",
    "\n",
    "\n",
    "train_features = train_features[features]\n",
    "test_features = test_features[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing for both methods, need to rerun this part when start a new method\n",
    "\n",
    "# Seperate data for San Juan\n",
    "sj_train_features = train_features.loc['sj']\n",
    "sj_test_features = test_features.loc['sj']\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = train_features.loc['iq']\n",
    "iq_test_features = test_features.loc['iq']\n",
    "iq_train_labels = train_labels.loc['iq']\n",
    "\n",
    "# fill nan with most recent value  could research and improve\n",
    "sj_train_features.fillna(method='ffill', inplace=True)\n",
    "sj_test_features.fillna(method='ffill', inplace=True)\n",
    "\n",
    "iq_train_features.fillna(method='ffill', inplace=True)\n",
    "iq_test_features.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "sj_train_features = sj_train_features.reset_index('weekofyear')\n",
    "sj_train_features = sj_train_features.reset_index('year')\n",
    "sj_train_labels = sj_train_labels.reset_index('weekofyear')\n",
    "sj_train_labels = sj_train_labels.reset_index('year')\n",
    "\n",
    "sj_test_features = sj_test_features.reset_index('weekofyear')\n",
    "sj_test_features = sj_test_features.reset_index('year')\n",
    "\n",
    "iq_train_features = iq_train_features.reset_index('weekofyear')\n",
    "iq_train_features = iq_train_features.reset_index('year')\n",
    "iq_train_labels = iq_train_labels.reset_index('weekofyear')\n",
    "iq_train_labels = iq_train_labels.reset_index('year')\n",
    "\n",
    "iq_test_features = iq_test_features.reset_index('weekofyear')\n",
    "iq_test_features = iq_test_features.reset_index('year')\n",
    "\n",
    "\n",
    "df = sj_train_features\n",
    "sj_val = df[656:]\n",
    "sj_train = df[:656]\n",
    "x_train = np.asarray(sj_train)\n",
    "x_val = np.asarray(sj_val)\n",
    "y_train = sj_train_labels['total_cases'][:656]\n",
    "y_val = sj_train_labels['total_cases'][656:]\n",
    "\n",
    "# log transform of cases\n",
    "#y_train = [np.log(i) if i > 0 else 0 for i in y_train]\n",
    "#y_val = [np.log(i) if i > 0 else 0 for i in y_val]\n",
    "\n",
    "x_total = np.concatenate((x_train,x_val),axis=0)\n",
    "\n",
    "y_total = np.asarray(sj_train_labels['total_cases'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  function to create environmental lags for approach 1 \n",
    "#  lag 1 specifies the farthest lag, lag2 specifies the closest lag\n",
    "def create_envlags(a,lag1,lag2,endpoints=False):\n",
    "    array = []\n",
    "    for i in range(lagmax,len(a)): \n",
    "        temp = a[i-lag1:i-lag2+1,2:]\n",
    "        temp = temp.flatten()\n",
    "\n",
    "        array.append(temp)\n",
    "    return np.asarray(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## San Juan Train Predict and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature preparation\n",
    "lagmax=5\n",
    "lagmin=3\n",
    "x_val = np.concatenate((x_train[-lagmax:],x_val))\n",
    "x_train = create_envlags(x_train,lagmax,lagmin)\n",
    "x_val = create_envlags(x_val,lagmax,lagmin)\n",
    "x_total = np.concatenate((x_train,x_val),axis=0)\n",
    "y_train= y_train[lagmax:]\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and plotting result for San Juan \n",
    "len1 = 655-lagmax\n",
    "len2 = 935-lagmax\n",
    "\n",
    "k3 = 0.5**2* RationalQuadratic(length_scale=1, length_scale_bounds=(1e-2, 30.0), alpha=10,alpha_bounds=(1e-1,100))\n",
    "#k4 = 1.* RBF(length_scale=[1.0 for i in range(24)], length_scale_bounds=(1e-2, 30)) + 1.**2 *ConstantKernel(0.1, (0.1, 10))*WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "k5 = ConstantKernel(0.1, (0.01, 10.0))*(DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)))\n",
    "k4 = ConstantKernel(0.1, (0.1, 30))*1* Matern(length_scale=1, length_scale_bounds=(1e-1, 30),nu=1.5)+ ConstantKernel(0.1, (0.1, 20))*WhiteKernel(noise_level=0.1**2,\n",
    "                  noise_level_bounds=(1e-3, 1e3))\n",
    "\n",
    "#kernel = k3*k5+ k4 \n",
    "kernel = k3*k5+k4\n",
    "gp3 = GaussianProcessRegressor(kernel=kernel,random_state=1)\n",
    "gp3.fit(x_train,y_train)\n",
    "print(gp3.kernel_)\n",
    "\n",
    "# Predict for the whole dataset (training and test)\n",
    "y_pred3, sigma = gp3.predict(x_total, return_std=True)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(range(len1), y_pred3[:len1], 'b-', label=u'Prediction')\n",
    "plt.plot(range(len1,len2), y_pred3[len1:len2],'r-',label=u'validation Prediction')\n",
    "plt.plot(range(len2+1), y_total[lagmax:], label='totoalcases')\n",
    "\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE score evaluation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_pred3[len1:len2],y_val[:280]))\n",
    "print(mean_absolute_error(y_pred3[:len1+1],y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iquitos train predict and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preparation for Iquitos\n",
    "split = 364\n",
    "df = iq_train_features\n",
    "iq_val = df[split:]\n",
    "iq_train = df[:split]\n",
    "x_train = np.asarray(iq_train)\n",
    "x_val = np.asarray(iq_val)\n",
    "y_train = iq_train_labels['total_cases'][:split]\n",
    "y_val = iq_train_labels['total_cases'][split:]\n",
    "x_total = np.concatenate((x_train,x_val),axis=0)\n",
    "y_total = np.asarray(iq_train_labels['total_cases'])\n",
    "\n",
    "lagmax=5\n",
    "lagmin=3\n",
    "x_val = np.concatenate((x_train[-lagmax:],x_val))\n",
    "x_train = create_envlags(x_train,lagmax,lagmin)\n",
    "x_val = create_envlags(x_val,lagmax,lagmin)\n",
    "x_total = np.concatenate((x_train,x_val),axis=0)\n",
    "y_train= y_train[lagmax:]\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and plotting for iquitos\n",
    "k3 = 1* RationalQuadratic(length_scale=1, length_scale_bounds=(1e-1, 30.0), alpha=10,alpha_bounds=(1e-1,100))\n",
    "k4 = 1.* RBF(length_scale=1, length_scale_bounds=(1e-2, 10)) + 1.**2 *ConstantKernel(0.1, (0.1, 10))*WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "k5 = ConstantKernel(0.1, (0.01, 10.0))*(DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)))\n",
    "\n",
    "\n",
    "kernel = k3+k5*k4\n",
    "\n",
    "# *ConstantKernel(0.1, (0.1, 10))\n",
    "gp = GaussianProcessRegressor(kernel=kernel,random_state=1)\n",
    "gp.fit(x_train,y_train)\n",
    "print(gp.kernel_)\n",
    "en1 = 364-lagmax\n",
    "len2 = 520-lagmax\n",
    "\n",
    "y_pred, sigma = gp.predict(x_total, return_std=True)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(range(len1), y_pred[:len1], 'b-', label=u'Prediction')\n",
    "plt.plot(range(len1,len2), y_pred[len1:len2],'r-',label=u'validation Prediction')\n",
    "plt.plot(range(len2), y_total[lagmax:], label='totoalcases')\n",
    "\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create lag features\n",
    "def prepare_features(a,b,lag1,lag2,lag_case,include_week,include_year):\n",
    "    array = []\n",
    "    offset = 2\n",
    "    if include_week:\n",
    "        offset = 1\n",
    "    if include_year:\n",
    "        offset = 0\n",
    "    for i in range(lagmax,len(a)): \n",
    "        \n",
    "        temp = a[i-lag1:i-lag2+1,offset:]\n",
    "        temp = temp.flatten()\n",
    "        temp1 = b[i-lag_case:i]\n",
    "       \n",
    "        temp2 = np.concatenate((a[i,:2],temp))\n",
    "        temp3 = np.concatenate((temp2,temp1))\n",
    "        \n",
    "        array.append(temp3)\n",
    "    return np.asarray(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used in recursive prediction\n",
    "def create_one_feature(a,b,i,lagmax,lagmin,lagcase,include_week,include_year):\n",
    "    offset = 2 \n",
    "    if include_week:\n",
    "        offset = 1\n",
    "    if include_year:\n",
    "        offset = 0\n",
    "    temp = a[i-lagmax:i-lagmin+1,offset:]\n",
    "    temp = temp.flatten()\n",
    "    temp1 = b[i-lagcase:i]\n",
    "    temp2 = np.concatenate((a[i,:2],temp))\n",
    "    temp3 = np.concatenate((temp2,temp1))\n",
    "    \n",
    "    return temp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## San juan train predict and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preparation for San juan\n",
    "lagmax=5\n",
    "lagmin=3\n",
    "lagcase=3\n",
    "include_year = True\n",
    "include_week = False\n",
    "x_train_l = prepare_features(x_train,y_train,lagmax,lagmin,lagcase,include_week,include_year)\n",
    "y_train_l= np.asarray(y_train[lagmax:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "k1 = 1. *ConstantKernel(0.1, (0.1, 10))*RationalQuadratic(length_scale=1,length_scale_bounds=(1e-2, 20.0), alpha=10,alpha_bounds=(1e-2,100))\n",
    "\n",
    "k3 = 1. * RBF(length_scale=[1.0 for i in range(20)] ,length_scale_bounds=(1e-1, 20.0))+1*ConstantKernel(0.1, (0.1, 10))*WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "\n",
    "k4 = ConstantKernel(0.1, (0.01, 10.0))*(DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)))\n",
    "\n",
    "#k5 = ConstantKernel(0.1, (0.01, 10.0))*(DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)))\n",
    "kernel = k1*k4+k3\n",
    "                                                                                                                   \n",
    "gp_t = GaussianProcessRegressor(kernel=kernel,random_state=1)\n",
    "gp_t.fit(x_train_l,y_train_l)\n",
    "print(gp_t.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "x_val_l = x_total[656-lagmax:936]\n",
    "y_val_pred = np.asarray(y_train[656-lagmax:])\n",
    "vallength = 280+lagmax\n",
    "\n",
    "val_sigma = []\n",
    "# recursive prediction\n",
    "for i in range(lagmax,vallength):\n",
    "    feature_val = create_one_feature(x_val_l,y_val_pred,i,lagmax,lagmin,lagcase,include_week,include_year)\n",
    "    #print(feature_val.shape)\n",
    "    predicted,sigma = gp_t.predict(feature_val.reshape(1,-1),return_std=True)\n",
    "    y_val_pred = np.concatenate((y_val_pred,predicted))\n",
    "    val_sigma.append(sigma)\n",
    "    \n",
    "y_val_pred = y_val_pred[lagmax:]\n",
    "val_sigma = np.asarray(val_sigma).flatten()\n",
    "\n",
    "y_train_pred,sigma_train = gp_t.predict(x_train_l,return_std=True)\n",
    "\n",
    "y_pred_total = np.concatenate((y_train_pred,y_val_pred))\n",
    "sigma = np.concatenate((sigma_train,val_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "train_val_split = 655\n",
    "total_length = 936\n",
    "\n",
    "\n",
    "plt.plot(range(train_val_split-lagmax+1), y_train_pred, 'b-', label=u'Prediction')\n",
    "plt.plot(range(train_val_split-lagmax+1,total_length-lagmax), y_val_pred,'r-',label=u'validation Prediction')\n",
    "plt.plot(range(total_length-lagmax), y_total[lagmax:], label='totoalcases')\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iquitos Train Predict and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 364\n",
    "df = iq_train_features\n",
    "iq_val = df[split:]\n",
    "iq_train = df[:split]\n",
    "x_train = np.asarray(iq_train)\n",
    "x_val = np.asarray(iq_val)\n",
    "y_train = iq_train_labels['total_cases'][:split]\n",
    "y_val = iq_train_labels['total_cases'][split:]\n",
    "x_total = np.concatenate((x_train,x_val),axis=0)\n",
    "y_total = np.asarray(iq_train_labels['total_cases'])\n",
    "\n",
    "x_train_l = prepare_features(x_train,y_train,lagmax,lagmin,lagcase,include_week,include_year)\n",
    "y_train_l= np.asarray(y_train[lagmax:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "k1 = 1.**2 *ConstantKernel(0.1, (0.1, 10))*RationalQuadratic(length_scale=1,length_scale_bounds=(1e-2, 20.0), alpha=10,alpha_bounds=(1e-2,100))\n",
    "\n",
    "k3 = 1. * RBF(length_scale=[1.0 for i in range(16)] ,length_scale_bounds=(1e-1, 20.0))+1.**2 *ConstantKernel(0.1, (0.1, 10))*WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e10))\n",
    "\n",
    "k4 = ConstantKernel(0.1, (0.01, 10.0))*(DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)))\n",
    "\n",
    "kernel = k3+k1*k4\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,random_state=1)\n",
    "gp.fit(x_train_l,y_train_l)\n",
    "print(gp.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "length= 520\n",
    "x_val_l = x_total[split-lagmax:520]\n",
    "y_val_pred = np.asarray(y_train[split-lagmax:])\n",
    "vallength = (length-split)+lagmax\n",
    "\n",
    "# recursive prediction\n",
    "for i in range(lagmax,vallength):\n",
    "    feature_val = create_one_feature(x_val_l,y_val_pred,i,lagmax,lagmin,lagcase,include_week,include_year)\n",
    "    #print(feature_val.shape)\n",
    "    predicted = gp.predict(feature_val.reshape(1,-1))\n",
    "    y_val_pred = np.concatenate((y_val_pred,predicted))\n",
    "\n",
    "y_val_pred = y_val_pred[lagmax:]\n",
    "y_train_pred = gp.predict(x_train_l)\n",
    "y_pred_total = np.concatenate((y_train_pred,y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "plt.plot(range(split-lagmax), y_train_pred, 'b-', label=u'Prediction')\n",
    "plt.plot(range(split-lagmax,length-lagmax), y_val_pred,'r-',label=u'validation Prediction')\n",
    "plt.plot(range(length-lagmax), y_total[lagmax:], label='totoalcases')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
